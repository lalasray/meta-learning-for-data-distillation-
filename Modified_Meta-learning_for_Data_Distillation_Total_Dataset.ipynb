{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import BatchSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784 # 28x28\n",
    "hidden_size = 500 \n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "#test_batch_size = 10000\n",
    "learning_rate = 0.001\n",
    "#SPC is for number of samples per class\n",
    "t1=[]\n",
    "t2=[]\n",
    "t3=[]\n",
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test list size is 10000\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset \n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))]),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))]))\n",
    "\n",
    "\n",
    "t0=test_dataset.targets\n",
    "t0 = t0.reshape(1, -1)\n",
    "t0 = t0.squeeze()\n",
    "t2=t0.tolist()\n",
    "print ( \"Test list size is\" ,len(t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Data loader\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size ,shuffle=False)\n",
    "\n",
    "print (len(test_loader))\n",
    "print (len(test_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.l1 = torch.nn.Linear(input_size, hidden_size) \n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.l2 = torch.nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [100/600], Loss: 0.4685\n",
      "Epoch [1/2], Step [200/600], Loss: 0.5386\n",
      "Epoch [1/2], Step [300/600], Loss: 0.4100\n",
      "Epoch [1/2], Step [400/600], Loss: 0.5052\n",
      "Epoch [1/2], Step [500/600], Loss: 0.5533\n",
      "Epoch [1/2], Step [600/600], Loss: 0.3194\n",
      "Epoch [2/2], Step [100/600], Loss: 0.2918\n",
      "Epoch [2/2], Step [200/600], Loss: 0.4281\n",
      "Epoch [2/2], Step [300/600], Loss: 0.3290\n",
      "Epoch [2/2], Step [400/600], Loss: 0.4691\n",
      "Epoch [2/2], Step [500/600], Loss: 0.5069\n",
      "Epoch [2/2], Step [600/600], Loss: 0.3003\n"
     ]
    }
   ],
   "source": [
    "# Train the model for all elements of the dataset\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # origin shape: [100, 1, 28, 28]\n",
    "        # resized: [100, 784]\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current total samples are 100\n",
      "of which  87 samples are correct\n",
      "Current total samples are 200\n",
      "of which  176 samples are correct\n",
      "Current total samples are 300\n",
      "of which  262 samples are correct\n",
      "Current total samples are 400\n",
      "of which  347 samples are correct\n",
      "Current total samples are 500\n",
      "of which  433 samples are correct\n",
      "Current total samples are 600\n",
      "of which  517 samples are correct\n",
      "Current total samples are 700\n",
      "of which  603 samples are correct\n",
      "Current total samples are 800\n",
      "of which  695 samples are correct\n",
      "Current total samples are 900\n",
      "of which  785 samples are correct\n",
      "Current total samples are 1000\n",
      "of which  862 samples are correct\n",
      "Current total samples are 1100\n",
      "of which  951 samples are correct\n",
      "Current total samples are 1200\n",
      "of which  1035 samples are correct\n",
      "Current total samples are 1300\n",
      "of which  1121 samples are correct\n",
      "Current total samples are 1400\n",
      "of which  1205 samples are correct\n",
      "Current total samples are 1500\n",
      "of which  1294 samples are correct\n",
      "Current total samples are 1600\n",
      "of which  1382 samples are correct\n",
      "Current total samples are 1700\n",
      "of which  1468 samples are correct\n",
      "Current total samples are 1800\n",
      "of which  1557 samples are correct\n",
      "Current total samples are 1900\n",
      "of which  1645 samples are correct\n",
      "Current total samples are 2000\n",
      "of which  1730 samples are correct\n",
      "Current total samples are 2100\n",
      "of which  1811 samples are correct\n",
      "Current total samples are 2200\n",
      "of which  1901 samples are correct\n",
      "Current total samples are 2300\n",
      "of which  1993 samples are correct\n",
      "Current total samples are 2400\n",
      "of which  2075 samples are correct\n",
      "Current total samples are 2500\n",
      "of which  2158 samples are correct\n",
      "Current total samples are 2600\n",
      "of which  2240 samples are correct\n",
      "Current total samples are 2700\n",
      "of which  2322 samples are correct\n",
      "Current total samples are 2800\n",
      "of which  2411 samples are correct\n",
      "Current total samples are 2900\n",
      "of which  2497 samples are correct\n",
      "Current total samples are 3000\n",
      "of which  2578 samples are correct\n",
      "Current total samples are 3100\n",
      "of which  2662 samples are correct\n",
      "Current total samples are 3200\n",
      "of which  2750 samples are correct\n",
      "Current total samples are 3300\n",
      "of which  2828 samples are correct\n",
      "Current total samples are 3400\n",
      "of which  2914 samples are correct\n",
      "Current total samples are 3500\n",
      "of which  2997 samples are correct\n",
      "Current total samples are 3600\n",
      "of which  3086 samples are correct\n",
      "Current total samples are 3700\n",
      "of which  3173 samples are correct\n",
      "Current total samples are 3800\n",
      "of which  3260 samples are correct\n",
      "Current total samples are 3900\n",
      "of which  3346 samples are correct\n",
      "Current total samples are 4000\n",
      "of which  3432 samples are correct\n",
      "Current total samples are 4100\n",
      "of which  3516 samples are correct\n",
      "Current total samples are 4200\n",
      "of which  3594 samples are correct\n",
      "Current total samples are 4300\n",
      "of which  3678 samples are correct\n",
      "Current total samples are 4400\n",
      "of which  3770 samples are correct\n",
      "Current total samples are 4500\n",
      "of which  3858 samples are correct\n",
      "Current total samples are 4600\n",
      "of which  3949 samples are correct\n",
      "Current total samples are 4700\n",
      "of which  4033 samples are correct\n",
      "Current total samples are 4800\n",
      "of which  4117 samples are correct\n",
      "Current total samples are 4900\n",
      "of which  4196 samples are correct\n",
      "Current total samples are 5000\n",
      "of which  4288 samples are correct\n",
      "Current total samples are 5100\n",
      "of which  4368 samples are correct\n",
      "Current total samples are 5200\n",
      "of which  4452 samples are correct\n",
      "Current total samples are 5300\n",
      "of which  4541 samples are correct\n",
      "Current total samples are 5400\n",
      "of which  4629 samples are correct\n",
      "Current total samples are 5500\n",
      "of which  4712 samples are correct\n",
      "Current total samples are 5600\n",
      "of which  4787 samples are correct\n",
      "Current total samples are 5700\n",
      "of which  4875 samples are correct\n",
      "Current total samples are 5800\n",
      "of which  4961 samples are correct\n",
      "Current total samples are 5900\n",
      "of which  5053 samples are correct\n",
      "Current total samples are 6000\n",
      "of which  5143 samples are correct\n",
      "Current total samples are 6100\n",
      "of which  5227 samples are correct\n",
      "Current total samples are 6200\n",
      "of which  5309 samples are correct\n",
      "Current total samples are 6300\n",
      "of which  5396 samples are correct\n",
      "Current total samples are 6400\n",
      "of which  5484 samples are correct\n",
      "Current total samples are 6500\n",
      "of which  5569 samples are correct\n",
      "Current total samples are 6600\n",
      "of which  5652 samples are correct\n",
      "Current total samples are 6700\n",
      "of which  5735 samples are correct\n",
      "Current total samples are 6800\n",
      "of which  5821 samples are correct\n",
      "Current total samples are 6900\n",
      "of which  5905 samples are correct\n",
      "Current total samples are 7000\n",
      "of which  5992 samples are correct\n",
      "Current total samples are 7100\n",
      "of which  6080 samples are correct\n",
      "Current total samples are 7200\n",
      "of which  6163 samples are correct\n",
      "Current total samples are 7300\n",
      "of which  6250 samples are correct\n",
      "Current total samples are 7400\n",
      "of which  6339 samples are correct\n",
      "Current total samples are 7500\n",
      "of which  6429 samples are correct\n",
      "Current total samples are 7600\n",
      "of which  6517 samples are correct\n",
      "Current total samples are 7700\n",
      "of which  6606 samples are correct\n",
      "Current total samples are 7800\n",
      "of which  6699 samples are correct\n",
      "Current total samples are 7900\n",
      "of which  6787 samples are correct\n",
      "Current total samples are 8000\n",
      "of which  6870 samples are correct\n",
      "Current total samples are 8100\n",
      "of which  6951 samples are correct\n",
      "Current total samples are 8200\n",
      "of which  7037 samples are correct\n",
      "Current total samples are 8300\n",
      "of which  7123 samples are correct\n",
      "Current total samples are 8400\n",
      "of which  7215 samples are correct\n",
      "Current total samples are 8500\n",
      "of which  7304 samples are correct\n",
      "Current total samples are 8600\n",
      "of which  7388 samples are correct\n",
      "Current total samples are 8700\n",
      "of which  7477 samples are correct\n",
      "Current total samples are 8800\n",
      "of which  7552 samples are correct\n",
      "Current total samples are 8900\n",
      "of which  7638 samples are correct\n",
      "Current total samples are 9000\n",
      "of which  7724 samples are correct\n",
      "Current total samples are 9100\n",
      "of which  7806 samples are correct\n",
      "Current total samples are 9200\n",
      "of which  7893 samples are correct\n",
      "Current total samples are 9300\n",
      "of which  7980 samples are correct\n",
      "Current total samples are 9400\n",
      "of which  8064 samples are correct\n",
      "Current total samples are 9500\n",
      "of which  8153 samples are correct\n",
      "Current total samples are 9600\n",
      "of which  8241 samples are correct\n",
      "Current total samples are 9700\n",
      "of which  8326 samples are correct\n",
      "Current total samples are 9800\n",
      "of which  8418 samples are correct\n",
      "Current total samples are 9900\n",
      "of which  8508 samples are correct\n",
      "Current total samples are 10000\n",
      "of which  8594 samples are correct\n",
      "10000\n",
      "Accuracy of the network on the given test images: 85.94 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "t3=[]\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        tpredict=predicted.tolist()\n",
    "        t3=t3+tpredict\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        print(\"Current total samples are\",n_samples,)\n",
    "        print(\"of which \",n_correct,\"samples are correct\")\n",
    "\n",
    "        \n",
    "print(len(t3))\n",
    "       \n",
    "acc = 100.0 * n_correct / n_samples\n",
    "print(f'Accuracy of the network on the given test images: {acc} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.82      1000\n",
      "           1       0.97      0.97      0.97      1000\n",
      "           2       0.80      0.76      0.78      1000\n",
      "           3       0.85      0.89      0.87      1000\n",
      "           4       0.80      0.73      0.77      1000\n",
      "           5       0.96      0.90      0.93      1000\n",
      "           6       0.67      0.60      0.63      1000\n",
      "           7       0.88      0.96      0.92      1000\n",
      "           8       0.94      0.96      0.95      1000\n",
      "           9       0.95      0.94      0.95      1000\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "#print(classification_report(labels, predicted, zero_division=1))\n",
    "print(classification_report(t2, t3, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[880   0  11  29   3   6  56   1  14   0]\n",
      " [  4 970   0  20   2   0   2   0   2   0]\n",
      " [ 22   1 764  15 102   1  89   1   5   0]\n",
      " [ 37  23   6 887  21   1  21   0   4   0]\n",
      " [  2   2  84  51 733   0 123   0   5   0]\n",
      " [  0   0   0   1   0 897   0  78   2  22]\n",
      " [201   2  86  29  54   2 599   0  27   0]\n",
      " [  0   0   0   0   0  12   0 960   0  28]\n",
      " [  4   0   5   8   1  12   3   7 960   0]\n",
      " [  1   0   0   0   0   5   0  50   0 944]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(t2,t3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
