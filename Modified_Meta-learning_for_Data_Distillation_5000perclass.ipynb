{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import BatchSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784 # 28x28\n",
    "hidden_size = 500 \n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "#test_batch_size = 10000\n",
    "learning_rate = 0.001\n",
    "spc=5000\n",
    "#SPC is for number of samples per class\n",
    "t1=[]\n",
    "t2=[]\n",
    "t3=[]\n",
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current list size is 5000\n",
      "5000  random samples for class 0 is added to the list\n",
      "Current list size is 10000\n",
      "5000  random samples for class 1 is added to the list\n",
      "Current list size is 15000\n",
      "5000  random samples for class 2 is added to the list\n",
      "Current list size is 20000\n",
      "5000  random samples for class 3 is added to the list\n",
      "Current list size is 25000\n",
      "5000  random samples for class 4 is added to the list\n",
      "Current list size is 30000\n",
      "5000  random samples for class 5 is added to the list\n",
      "Current list size is 35000\n",
      "5000  random samples for class 6 is added to the list\n",
      "Current list size is 40000\n",
      "5000  random samples for class 7 is added to the list\n",
      "Current list size is 45000\n",
      "5000  random samples for class 8 is added to the list\n",
      "Current list size is 50000\n",
      "5000  random samples for class 9 is added to the list\n",
      "Test list size is 10000\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset \n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))]),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))]))\n",
    "\n",
    "\n",
    "for i in range (10):\n",
    "    t0=(train_dataset.targets==i).nonzero(as_tuple=False)\n",
    "    t0 = t0.reshape(1, -1)\n",
    "    t0 = t0.squeeze()\n",
    "    t0=t0.tolist()\n",
    "    np.random.shuffle(t0)\n",
    "    t0=t0[0:spc]\n",
    "    t1=t1+t0\n",
    "    print ( \"Current list size is\" ,len(t1))\n",
    "    print (spc,\" random samples for class\" ,i, \"is added to the list\")\n",
    "\n",
    "train_subset = torch.utils.data.Subset(train_dataset,t1)\n",
    "#train_dataset0.targets = train_dataset.targets[t1]\n",
    "#train_dataset0.data = train_dataset.data[t1]\n",
    "\n",
    "t0=test_dataset.targets\n",
    "t0 = t0.reshape(1, -1)\n",
    "t0 = t0.squeeze()\n",
    "t2=t0.tolist()\n",
    "print ( \"Test list size is\" ,len(t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Data loader\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size ,shuffle=False)\n",
    "\n",
    "print (len(test_loader))\n",
    "print (len(test_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.l1 = torch.nn.Linear(input_size, hidden_size) \n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.l2 = torch.nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [100/500], Loss: 0.0000\n",
      "Epoch [1/2], Step [200/500], Loss: 0.0010\n",
      "Epoch [1/2], Step [300/500], Loss: 0.0000\n",
      "Epoch [1/2], Step [400/500], Loss: 0.0000\n",
      "Epoch [1/2], Step [500/500], Loss: 0.0000\n",
      "Epoch [2/2], Step [100/500], Loss: 0.0001\n",
      "Epoch [2/2], Step [200/500], Loss: 0.0111\n",
      "Epoch [2/2], Step [300/500], Loss: 0.0000\n",
      "Epoch [2/2], Step [400/500], Loss: 0.0000\n",
      "Epoch [2/2], Step [500/500], Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Train the model for all elements of the dataset\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # origin shape: [100, 1, 28, 28]\n",
    "        # resized: [100, 784]\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current total samples are 100\n",
      "of which  8 samples are correct\n",
      "Current total samples are 200\n",
      "of which  21 samples are correct\n",
      "Current total samples are 300\n",
      "of which  33 samples are correct\n",
      "Current total samples are 400\n",
      "of which  46 samples are correct\n",
      "Current total samples are 500\n",
      "of which  62 samples are correct\n",
      "Current total samples are 600\n",
      "of which  74 samples are correct\n",
      "Current total samples are 700\n",
      "of which  86 samples are correct\n",
      "Current total samples are 800\n",
      "of which  98 samples are correct\n",
      "Current total samples are 900\n",
      "of which  109 samples are correct\n",
      "Current total samples are 1000\n",
      "of which  118 samples are correct\n",
      "Current total samples are 1100\n",
      "of which  134 samples are correct\n",
      "Current total samples are 1200\n",
      "of which  145 samples are correct\n",
      "Current total samples are 1300\n",
      "of which  157 samples are correct\n",
      "Current total samples are 1400\n",
      "of which  167 samples are correct\n",
      "Current total samples are 1500\n",
      "of which  181 samples are correct\n",
      "Current total samples are 1600\n",
      "of which  191 samples are correct\n",
      "Current total samples are 1700\n",
      "of which  200 samples are correct\n",
      "Current total samples are 1800\n",
      "of which  215 samples are correct\n",
      "Current total samples are 1900\n",
      "of which  228 samples are correct\n",
      "Current total samples are 2000\n",
      "of which  242 samples are correct\n",
      "Current total samples are 2100\n",
      "of which  259 samples are correct\n",
      "Current total samples are 2200\n",
      "of which  274 samples are correct\n",
      "Current total samples are 2300\n",
      "of which  287 samples are correct\n",
      "Current total samples are 2400\n",
      "of which  297 samples are correct\n",
      "Current total samples are 2500\n",
      "of which  313 samples are correct\n",
      "Current total samples are 2600\n",
      "of which  327 samples are correct\n",
      "Current total samples are 2700\n",
      "of which  332 samples are correct\n",
      "Current total samples are 2800\n",
      "of which  342 samples are correct\n",
      "Current total samples are 2900\n",
      "of which  350 samples are correct\n",
      "Current total samples are 3000\n",
      "of which  358 samples are correct\n",
      "Current total samples are 3100\n",
      "of which  370 samples are correct\n",
      "Current total samples are 3200\n",
      "of which  376 samples are correct\n",
      "Current total samples are 3300\n",
      "of which  387 samples are correct\n",
      "Current total samples are 3400\n",
      "of which  401 samples are correct\n",
      "Current total samples are 3500\n",
      "of which  409 samples are correct\n",
      "Current total samples are 3600\n",
      "of which  418 samples are correct\n",
      "Current total samples are 3700\n",
      "of which  434 samples are correct\n",
      "Current total samples are 3800\n",
      "of which  449 samples are correct\n",
      "Current total samples are 3900\n",
      "of which  462 samples are correct\n",
      "Current total samples are 4000\n",
      "of which  472 samples are correct\n",
      "Current total samples are 4100\n",
      "of which  484 samples are correct\n",
      "Current total samples are 4200\n",
      "of which  496 samples are correct\n",
      "Current total samples are 4300\n",
      "of which  506 samples are correct\n",
      "Current total samples are 4400\n",
      "of which  517 samples are correct\n",
      "Current total samples are 4500\n",
      "of which  536 samples are correct\n",
      "Current total samples are 4600\n",
      "of which  547 samples are correct\n",
      "Current total samples are 4700\n",
      "of which  559 samples are correct\n",
      "Current total samples are 4800\n",
      "of which  565 samples are correct\n",
      "Current total samples are 4900\n",
      "of which  585 samples are correct\n",
      "Current total samples are 5000\n",
      "of which  600 samples are correct\n",
      "Current total samples are 5100\n",
      "of which  613 samples are correct\n",
      "Current total samples are 5200\n",
      "of which  628 samples are correct\n",
      "Current total samples are 5300\n",
      "of which  634 samples are correct\n",
      "Current total samples are 5400\n",
      "of which  651 samples are correct\n",
      "Current total samples are 5500\n",
      "of which  670 samples are correct\n",
      "Current total samples are 5600\n",
      "of which  679 samples are correct\n",
      "Current total samples are 5700\n",
      "of which  690 samples are correct\n",
      "Current total samples are 5800\n",
      "of which  705 samples are correct\n",
      "Current total samples are 5900\n",
      "of which  719 samples are correct\n",
      "Current total samples are 6000\n",
      "of which  731 samples are correct\n",
      "Current total samples are 6100\n",
      "of which  749 samples are correct\n",
      "Current total samples are 6200\n",
      "of which  766 samples are correct\n",
      "Current total samples are 6300\n",
      "of which  779 samples are correct\n",
      "Current total samples are 6400\n",
      "of which  792 samples are correct\n",
      "Current total samples are 6500\n",
      "of which  799 samples are correct\n",
      "Current total samples are 6600\n",
      "of which  805 samples are correct\n",
      "Current total samples are 6700\n",
      "of which  820 samples are correct\n",
      "Current total samples are 6800\n",
      "of which  840 samples are correct\n",
      "Current total samples are 6900\n",
      "of which  850 samples are correct\n",
      "Current total samples are 7000\n",
      "of which  862 samples are correct\n",
      "Current total samples are 7100\n",
      "of which  878 samples are correct\n",
      "Current total samples are 7200\n",
      "of which  894 samples are correct\n",
      "Current total samples are 7300\n",
      "of which  908 samples are correct\n",
      "Current total samples are 7400\n",
      "of which  922 samples are correct\n",
      "Current total samples are 7500\n",
      "of which  935 samples are correct\n",
      "Current total samples are 7600\n",
      "of which  953 samples are correct\n",
      "Current total samples are 7700\n",
      "of which  967 samples are correct\n",
      "Current total samples are 7800\n",
      "of which  979 samples are correct\n",
      "Current total samples are 7900\n",
      "of which  991 samples are correct\n",
      "Current total samples are 8000\n",
      "of which  1000 samples are correct\n",
      "Current total samples are 8100\n",
      "of which  1015 samples are correct\n",
      "Current total samples are 8200\n",
      "of which  1027 samples are correct\n",
      "Current total samples are 8300\n",
      "of which  1034 samples are correct\n",
      "Current total samples are 8400\n",
      "of which  1047 samples are correct\n",
      "Current total samples are 8500\n",
      "of which  1063 samples are correct\n",
      "Current total samples are 8600\n",
      "of which  1072 samples are correct\n",
      "Current total samples are 8700\n",
      "of which  1082 samples are correct\n",
      "Current total samples are 8800\n",
      "of which  1096 samples are correct\n",
      "Current total samples are 8900\n",
      "of which  1108 samples are correct\n",
      "Current total samples are 9000\n",
      "of which  1128 samples are correct\n",
      "Current total samples are 9100\n",
      "of which  1140 samples are correct\n",
      "Current total samples are 9200\n",
      "of which  1155 samples are correct\n",
      "Current total samples are 9300\n",
      "of which  1167 samples are correct\n",
      "Current total samples are 9400\n",
      "of which  1183 samples are correct\n",
      "Current total samples are 9500\n",
      "of which  1193 samples are correct\n",
      "Current total samples are 9600\n",
      "of which  1206 samples are correct\n",
      "Current total samples are 9700\n",
      "of which  1221 samples are correct\n",
      "Current total samples are 9800\n",
      "of which  1230 samples are correct\n",
      "Current total samples are 9900\n",
      "of which  1240 samples are correct\n",
      "Current total samples are 10000\n",
      "of which  1255 samples are correct\n",
      "10000\n",
      "Accuracy of the network on the given test images: 12.55 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "t3=[]\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        tpredict=predicted.tolist()\n",
    "        t3=t3+tpredict\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        print(\"Current total samples are\",n_samples,)\n",
    "        print(\"of which \",n_correct,\"samples are correct\")\n",
    "\n",
    "        \n",
    "print(len(t3))\n",
    "       \n",
    "acc = 100.0 * n_correct / n_samples\n",
    "print(f'Accuracy of the network on the given test images: {acc} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00      1000\n",
      "           1       1.00      0.00      0.00      1000\n",
      "           2       1.00      0.00      0.00      1000\n",
      "           3       0.19      0.11      0.14      1000\n",
      "           4       0.00      0.00      0.00      1000\n",
      "           5       1.00      0.00      0.00      1000\n",
      "           6       0.10      0.06      0.07      1000\n",
      "           7       0.00      0.00      0.00      1000\n",
      "           8       0.03      0.09      0.05      1000\n",
      "           9       0.17      1.00      0.28      1000\n",
      "\n",
      "    accuracy                           0.13     10000\n",
      "   macro avg       0.45      0.13      0.05     10000\n",
      "weighted avg       0.45      0.13      0.05     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "#print(classification_report(labels, predicted, zero_division=1))\n",
    "print(classification_report(t2, t3, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    1    6    0  355    1  318  319]\n",
      " [   0    0    0  470   49    0   20    0   97  364]\n",
      " [   0    0    0    0    0    0   20    0  614  366]\n",
      " [   0    0    0  110   53    0  107    0  291  439]\n",
      " [   0    0    0    0    0    0   14    0  792  194]\n",
      " [   0    0    0    0    0    0    0    0    0 1000]\n",
      " [   0    0    0    3    1    0   56    0  498  442]\n",
      " [   0    0    0    0    0    0    0    0    0 1000]\n",
      " [   0    0    0    0    0    0    1    0   90  909]\n",
      " [   0    0    0    0    0    0    0    0    1  999]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(t2,t3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
