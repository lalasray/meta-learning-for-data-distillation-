{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import BatchSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784 # 28x28\n",
    "hidden_size = 500 \n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "#test_batch_size = 10000\n",
    "learning_rate = 0.001\n",
    "spc=1000\n",
    "#SPC is for number of samples per class\n",
    "t1=[]\n",
    "t2=[]\n",
    "t3=[]\n",
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current list size is 1000\n",
      "1000  random samples for class 0 is added to the list\n",
      "Current list size is 2000\n",
      "1000  random samples for class 1 is added to the list\n",
      "Current list size is 3000\n",
      "1000  random samples for class 2 is added to the list\n",
      "Current list size is 4000\n",
      "1000  random samples for class 3 is added to the list\n",
      "Current list size is 5000\n",
      "1000  random samples for class 4 is added to the list\n",
      "Current list size is 6000\n",
      "1000  random samples for class 5 is added to the list\n",
      "Current list size is 7000\n",
      "1000  random samples for class 6 is added to the list\n",
      "Current list size is 8000\n",
      "1000  random samples for class 7 is added to the list\n",
      "Current list size is 9000\n",
      "1000  random samples for class 8 is added to the list\n",
      "Current list size is 10000\n",
      "1000  random samples for class 9 is added to the list\n",
      "Test list size is 10000\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset \n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))]),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))]))\n",
    "\n",
    "\n",
    "for i in range (10):\n",
    "    t0=(train_dataset.targets==i).nonzero(as_tuple=False)\n",
    "    t0 = t0.reshape(1, -1)\n",
    "    t0 = t0.squeeze()\n",
    "    t0=t0.tolist()\n",
    "    np.random.shuffle(t0)\n",
    "    t0=t0[0:spc]\n",
    "    t1=t1+t0\n",
    "    print ( \"Current list size is\" ,len(t1))\n",
    "    print (spc,\" random samples for class\" ,i, \"is added to the list\")\n",
    "\n",
    "train_subset = torch.utils.data.Subset(train_dataset,t1)\n",
    "#train_dataset0.targets = train_dataset.targets[t1]\n",
    "#train_dataset0.data = train_dataset.data[t1]\n",
    "\n",
    "t0=test_dataset.targets\n",
    "t0 = t0.reshape(1, -1)\n",
    "t0 = t0.squeeze()\n",
    "t2=t0.tolist()\n",
    "print ( \"Test list size is\" ,len(t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Data loader\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size ,shuffle=False)\n",
    "\n",
    "print (len(test_loader))\n",
    "print (len(test_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.l1 = torch.nn.Linear(input_size, hidden_size) \n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.l2 = torch.nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [100/100], Loss: 0.6564\n",
      "Epoch [2/2], Step [100/100], Loss: 0.1131\n"
     ]
    }
   ],
   "source": [
    "# Train the model for all elements of the dataset\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # origin shape: [100, 1, 28, 28]\n",
    "        # resized: [100, 784]\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current total samples are 100\n",
      "of which  16 samples are correct\n",
      "Current total samples are 200\n",
      "of which  32 samples are correct\n",
      "Current total samples are 300\n",
      "of which  49 samples are correct\n",
      "Current total samples are 400\n",
      "of which  62 samples are correct\n",
      "Current total samples are 500\n",
      "of which  83 samples are correct\n",
      "Current total samples are 600\n",
      "of which  104 samples are correct\n",
      "Current total samples are 700\n",
      "of which  121 samples are correct\n",
      "Current total samples are 800\n",
      "of which  143 samples are correct\n",
      "Current total samples are 900\n",
      "of which  160 samples are correct\n",
      "Current total samples are 1000\n",
      "of which  171 samples are correct\n",
      "Current total samples are 1100\n",
      "of which  190 samples are correct\n",
      "Current total samples are 1200\n",
      "of which  205 samples are correct\n",
      "Current total samples are 1300\n",
      "of which  219 samples are correct\n",
      "Current total samples are 1400\n",
      "of which  234 samples are correct\n",
      "Current total samples are 1500\n",
      "of which  249 samples are correct\n",
      "Current total samples are 1600\n",
      "of which  267 samples are correct\n",
      "Current total samples are 1700\n",
      "of which  280 samples are correct\n",
      "Current total samples are 1800\n",
      "of which  299 samples are correct\n",
      "Current total samples are 1900\n",
      "of which  316 samples are correct\n",
      "Current total samples are 2000\n",
      "of which  338 samples are correct\n",
      "Current total samples are 2100\n",
      "of which  358 samples are correct\n",
      "Current total samples are 2200\n",
      "of which  374 samples are correct\n",
      "Current total samples are 2300\n",
      "of which  392 samples are correct\n",
      "Current total samples are 2400\n",
      "of which  413 samples are correct\n",
      "Current total samples are 2500\n",
      "of which  435 samples are correct\n",
      "Current total samples are 2600\n",
      "of which  454 samples are correct\n",
      "Current total samples are 2700\n",
      "of which  467 samples are correct\n",
      "Current total samples are 2800\n",
      "of which  488 samples are correct\n",
      "Current total samples are 2900\n",
      "of which  503 samples are correct\n",
      "Current total samples are 3000\n",
      "of which  520 samples are correct\n",
      "Current total samples are 3100\n",
      "of which  542 samples are correct\n",
      "Current total samples are 3200\n",
      "of which  558 samples are correct\n",
      "Current total samples are 3300\n",
      "of which  572 samples are correct\n",
      "Current total samples are 3400\n",
      "of which  596 samples are correct\n",
      "Current total samples are 3500\n",
      "of which  609 samples are correct\n",
      "Current total samples are 3600\n",
      "of which  624 samples are correct\n",
      "Current total samples are 3700\n",
      "of which  645 samples are correct\n",
      "Current total samples are 3800\n",
      "of which  668 samples are correct\n",
      "Current total samples are 3900\n",
      "of which  690 samples are correct\n",
      "Current total samples are 4000\n",
      "of which  707 samples are correct\n",
      "Current total samples are 4100\n",
      "of which  727 samples are correct\n",
      "Current total samples are 4200\n",
      "of which  744 samples are correct\n",
      "Current total samples are 4300\n",
      "of which  762 samples are correct\n",
      "Current total samples are 4400\n",
      "of which  782 samples are correct\n",
      "Current total samples are 4500\n",
      "of which  807 samples are correct\n",
      "Current total samples are 4600\n",
      "of which  828 samples are correct\n",
      "Current total samples are 4700\n",
      "of which  848 samples are correct\n",
      "Current total samples are 4800\n",
      "of which  859 samples are correct\n",
      "Current total samples are 4900\n",
      "of which  886 samples are correct\n",
      "Current total samples are 5000\n",
      "of which  910 samples are correct\n",
      "Current total samples are 5100\n",
      "of which  923 samples are correct\n",
      "Current total samples are 5200\n",
      "of which  946 samples are correct\n",
      "Current total samples are 5300\n",
      "of which  956 samples are correct\n",
      "Current total samples are 5400\n",
      "of which  984 samples are correct\n",
      "Current total samples are 5500\n",
      "of which  1005 samples are correct\n",
      "Current total samples are 5600\n",
      "of which  1019 samples are correct\n",
      "Current total samples are 5700\n",
      "of which  1034 samples are correct\n",
      "Current total samples are 5800\n",
      "of which  1052 samples are correct\n",
      "Current total samples are 5900\n",
      "of which  1070 samples are correct\n",
      "Current total samples are 6000\n",
      "of which  1089 samples are correct\n",
      "Current total samples are 6100\n",
      "of which  1111 samples are correct\n",
      "Current total samples are 6200\n",
      "of which  1132 samples are correct\n",
      "Current total samples are 6300\n",
      "of which  1146 samples are correct\n",
      "Current total samples are 6400\n",
      "of which  1161 samples are correct\n",
      "Current total samples are 6500\n",
      "of which  1176 samples are correct\n",
      "Current total samples are 6600\n",
      "of which  1191 samples are correct\n",
      "Current total samples are 6700\n",
      "of which  1215 samples are correct\n",
      "Current total samples are 6800\n",
      "of which  1237 samples are correct\n",
      "Current total samples are 6900\n",
      "of which  1255 samples are correct\n",
      "Current total samples are 7000\n",
      "of which  1272 samples are correct\n",
      "Current total samples are 7100\n",
      "of which  1292 samples are correct\n",
      "Current total samples are 7200\n",
      "of which  1310 samples are correct\n",
      "Current total samples are 7300\n",
      "of which  1328 samples are correct\n",
      "Current total samples are 7400\n",
      "of which  1348 samples are correct\n",
      "Current total samples are 7500\n",
      "of which  1372 samples are correct\n",
      "Current total samples are 7600\n",
      "of which  1394 samples are correct\n",
      "Current total samples are 7700\n",
      "of which  1410 samples are correct\n",
      "Current total samples are 7800\n",
      "of which  1425 samples are correct\n",
      "Current total samples are 7900\n",
      "of which  1440 samples are correct\n",
      "Current total samples are 8000\n",
      "of which  1454 samples are correct\n",
      "Current total samples are 8100\n",
      "of which  1474 samples are correct\n",
      "Current total samples are 8200\n",
      "of which  1491 samples are correct\n",
      "Current total samples are 8300\n",
      "of which  1504 samples are correct\n",
      "Current total samples are 8400\n",
      "of which  1523 samples are correct\n",
      "Current total samples are 8500\n",
      "of which  1545 samples are correct\n",
      "Current total samples are 8600\n",
      "of which  1566 samples are correct\n",
      "Current total samples are 8700\n",
      "of which  1585 samples are correct\n",
      "Current total samples are 8800\n",
      "of which  1602 samples are correct\n",
      "Current total samples are 8900\n",
      "of which  1619 samples are correct\n",
      "Current total samples are 9000\n",
      "of which  1645 samples are correct\n",
      "Current total samples are 9100\n",
      "of which  1668 samples are correct\n",
      "Current total samples are 9200\n",
      "of which  1689 samples are correct\n",
      "Current total samples are 9300\n",
      "of which  1707 samples are correct\n",
      "Current total samples are 9400\n",
      "of which  1730 samples are correct\n",
      "Current total samples are 9500\n",
      "of which  1749 samples are correct\n",
      "Current total samples are 9600\n",
      "of which  1771 samples are correct\n",
      "Current total samples are 9700\n",
      "of which  1793 samples are correct\n",
      "Current total samples are 9800\n",
      "of which  1807 samples are correct\n",
      "Current total samples are 9900\n",
      "of which  1825 samples are correct\n",
      "Current total samples are 10000\n",
      "of which  1850 samples are correct\n",
      "10000\n",
      "Accuracy of the network on the given test images: 18.5 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "t3=[]\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        tpredict=predicted.tolist()\n",
    "        t3=t3+tpredict\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        print(\"Current total samples are\",n_samples,)\n",
    "        print(\"of which \",n_correct,\"samples are correct\")\n",
    "\n",
    "        \n",
    "print(len(t3))\n",
    "       \n",
    "acc = 100.0 * n_correct / n_samples\n",
    "print(f'Accuracy of the network on the given test images: {acc} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1000\n",
      "           1       1.00      0.00      0.00      1000\n",
      "           2       1.00      0.00      0.00      1000\n",
      "           3       1.00      0.00      0.00      1000\n",
      "           4       0.00      0.00      0.00      1000\n",
      "           5       1.00      0.00      0.00      1000\n",
      "           6       0.07      0.05      0.06      1000\n",
      "           7       0.00      0.00      0.00      1000\n",
      "           8       0.15      0.80      0.25      1000\n",
      "           9       0.30      0.99      0.47      1000\n",
      "\n",
      "    accuracy                           0.18     10000\n",
      "   macro avg       0.45      0.18      0.08     10000\n",
      "weighted avg       0.45      0.18      0.08     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "#print(classification_report(labels, predicted, zero_division=1))\n",
    "print(classification_report(t2, t3, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0  347    4  623   26]\n",
      " [   0    0    0    0  341    0  111  120  425    3]\n",
      " [   0    0    0    0    0    0   37    0  958    5]\n",
      " [   0    0    0    0   22    0  190    2  762   24]\n",
      " [   0    0    0    0    0    0    7    0  988    5]\n",
      " [   0    0    0    0    0    0    0    0    6  994]\n",
      " [   0    0    0    0    0    0   52    1  924   23]\n",
      " [   0    0    0    0    0    0    0    0    0 1000]\n",
      " [   0    0    0    0    0    0    0    0  804  196]\n",
      " [   1    0    0    0    0    0    0    0    5  994]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(t2,t3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
